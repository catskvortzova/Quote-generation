{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\nimport datetime\nimport random\nimport traceback\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\n\n\ndef init_random_seed(value=0):\n    random.seed(value)\n    np.random.seed(value)\n    torch.manual_seed(value)\n    torch.cuda.manual_seed(value)\n    torch.backends.cudnn.deterministic = True\n\n\ndef copy_data_to_device(data, device):\n    if torch.is_tensor(data):\n        return data.to(device)\n    elif isinstance(data, (list, tuple)):\n        return [copy_data_to_device(elem, device) for elem in data]\n    raise ValueError('Недопустимый тип данных {}'.format(type(data)))\n\n\ndef print_grad_stats(model):\n    mean = 0\n    std = 0\n    norm = 1e-5\n    for param in model.parameters():\n        grad = getattr(param, 'grad', None)\n        if grad is not None:\n            mean += grad.data.abs().mean()\n            std += grad.data.std()\n            norm += 1\n    mean /= norm\n    std /= norm\n    print(f'Mean grad {mean}, std {std}, n {norm}')\n\n\ndef train_eval_loop(model, train_dataset, val_dataset, criterion,\n                    lr=1e-4, epoch_n=10, batch_size=32,\n                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n                    max_batches_per_epoch_train=10000,\n                    max_batches_per_epoch_val=1000,\n                    data_loader_ctor=DataLoader,\n                    optimizer_ctor=None,\n                    lr_scheduler_ctor=None,\n                    shuffle_train=True,\n                    dataloader_workers_n=0):\n    \"\"\"\n    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n    :param model: torch.nn.Module - обучаемая модель\n    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n    :param criterion: функция потерь для настройки модели\n    :param lr: скорость обучения\n    :param epoch_n: максимальное количество эпох\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n        отсутствие улучшения модели, чтобы обучение продолжалось.\n    :param l2_reg_alpha: коэффициент L2-регуляризации\n    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n        (по умолчанию torch.utils.data.DataLoader)\n    :return: кортеж из двух элементов:\n        - среднее значение функции потерь на валидации на лучшей эпохе\n        - лучшая модель\n    \"\"\"\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    device = torch.device(device)\n    model.to(device)\n\n    if optimizer_ctor is None:\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n    else:\n        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n\n    if lr_scheduler_ctor is not None:\n        lr_scheduler = lr_scheduler_ctor(optimizer)\n    else:\n        lr_scheduler = None\n\n    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n                                        num_workers=dataloader_workers_n)\n    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n                                      num_workers=dataloader_workers_n)\n\n    best_val_loss = float('inf')\n    best_epoch_i = 0\n    best_model = copy.deepcopy(model)\n\n    for epoch_i in range(epoch_n):\n        try:\n            epoch_start = datetime.datetime.now()\n            print('Эпоха {}'.format(epoch_i))\n\n            model.train()\n            mean_train_loss = 0\n            train_batches_n = 0\n            for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n                if batch_i > max_batches_per_epoch_train:\n                    break\n\n                batch_x = copy_data_to_device(batch_x, device)\n                batch_y = copy_data_to_device(batch_y, device)\n\n                pred = model(batch_x)\n                loss = criterion(pred, batch_y)\n\n                model.zero_grad()\n                loss.backward()\n\n                optimizer.step()\n\n                mean_train_loss += float(loss)\n                train_batches_n += 1\n\n            mean_train_loss /= train_batches_n\n            print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\n            print('Среднее значение функции потерь на обучении', mean_train_loss)\n\n\n\n            model.eval()\n            mean_val_loss = 0\n            val_batches_n = 0\n\n            with torch.no_grad():\n                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n                    if batch_i > max_batches_per_epoch_val:\n                        break\n\n                    batch_x = copy_data_to_device(batch_x, device)\n                    batch_y = copy_data_to_device(batch_y, device)\n\n                    pred = model(batch_x)\n                    loss = criterion(pred, batch_y)\n\n                    mean_val_loss += float(loss)\n                    val_batches_n += 1\n\n            mean_val_loss /= val_batches_n\n            print('Среднее значение функции потерь на валидации', mean_val_loss)\n\n            if mean_val_loss < best_val_loss:\n                best_epoch_i = epoch_i\n                best_val_loss = mean_val_loss\n                best_model = copy.deepcopy(model)\n                print('Новая лучшая модель!')\n            elif epoch_i - best_epoch_i > early_stopping_patience:\n                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n                    early_stopping_patience))\n                break\n\n            if lr_scheduler is not None:\n                lr_scheduler.step(mean_val_loss)\n\n            print()\n        except KeyboardInterrupt:\n            print('Досрочно остановлено пользователем')\n            break\n        except Exception as ex:\n            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n            break\n\n    return best_val_loss, best_model\n\n\ndef predict_with_model(model, dataset, device=None, batch_size=32, num_workers=0, return_labels=False):\n    \"\"\"\n    :param model: torch.nn.Module - обученная модель\n    :param dataset: torch.utils.data.Dataset - данные для применения модели\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :return: numpy.array размерности len(dataset) x *\n    \"\"\"\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    results_by_batch = []\n\n    device = torch.device(device)\n    model.to(device)\n    model.eval()\n\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    labels = []\n    with torch.no_grad():\n        import tqdm\n        for batch_x, batch_y in tqdm.tqdm(dataloader, total=len(dataset)/batch_size):\n            batch_x = copy_data_to_device(batch_x, device)\n\n            if return_labels:\n                labels.append(batch_y.numpy())\n\n            batch_pred = model(batch_x)\n            results_by_batch.append(batch_pred.detach().cpu().numpy())\n\n    if return_labels:\n        return np.concatenate(results_by_batch, 0), np.concatenate(labels, 0)\n    else:\n        return np.concatenate(results_by_batch, 0)\n\n\n\n","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PROGRAM"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install youtokentome","execution_count":35,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: youtokentome in /opt/conda/lib/python3.6/site-packages (1.0.6)\r\nRequirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.6/site-packages (from youtokentome) (7.1.1)\r\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import pandas as pd\nimport re\nimport numpy as np\nfrom itertools import chain\n\nimport torch, torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom torch.utils.data import Dataset\nimport random\nimport youtokentome as yttm","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load data and preparing data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filename = '/kaggle/input/texts-datasets/texts.txt'\nwith open(filename) as input_file:\n    phrases = input_file.read().split('\\n')\n    phrases = [' ' + line[:-1] for line in phrases]","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quotes = pd.read_csv('/kaggle/input/texts-datasets/quotes_base.csv')\nphrases+= list(quotes.Quote.values)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phrases = phrases[9:]","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_text_to_file(texts,filename):\n    with open(filename,'w') as outf:\n        outf.write('\\n'.join(texts))  ","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TOKEN_RE = re.compile(r\"[a-zA-Z]+\")\n\n\n\ndef tokenize_text_simple_regex(text,min_token_size=0):\n    text = text.lower()\n    text = text.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\").replace(\"'d\",\" would\")\n    text = re.sub(r\"([0-9]+)000000\", r\"\\1m\", text)\n    text = re.sub(r\"([0-9]+)000\", r\"\\1k\", text)\n    \n    all_tokens = TOKEN_RE.findall(text)\n    return [token for token in all_tokens if len(token)>=min_token_size]\n    \ndef tokenize_text(corpus,tokenizer=tokenize_text_simple_regex,**tokenizer_kwargs):\n    return [tokenizer(txt,**tokenizer_kwargs) for txt in corpus]","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phrase_token = tokenize_text(phrases)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phrase_token = [ph for ph in phrase_token if len(ph)<30 and len(ph)>3]","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_phrases = [' '.join(send) for send in phrase_token]\nlen(new_phrases)","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"301317"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_phrases = new_phrases[:40000]","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.shuffle(new_phrases)\n\nSPLIT = int(len(new_phrases) * 0.7)\n\ntrain_data = new_phrases[:SPLIT]\ntest_data = new_phrases[SPLIT:]","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Size of train dataset: {}\".format(len(train_data)))\nprint(\"Size of test dataset: {}\".format(len(test_data)))","execution_count":47,"outputs":[{"output_type":"stream","text":"Size of train dataset: 28000\nSize of test dataset: 12000\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Tokenize text with BPE"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_text_to_file(texts,filename):\n    with open(filename,'w') as outf:\n        outf.write('\\n'.join(texts))     ","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FILE_BPE = 'quotes.yttm'\nTRAIN_TEXT_FILENAME = 'train_quotes.txt'\nsave_text_to_file(train_data,TRAIN_TEXT_FILENAME)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yttm.BPE.train(data = TRAIN_TEXT_FILENAME,vocab_size = 1500,model = FILE_BPE )","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"<youtokentome.youtokentome.BPE at 0x7f2bb843c630>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = yttm.BPE(FILE_BPE)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_token_ids = tokenizer.encode(train_data, bos = True, eos = True)\ntest_token_ids = tokenizer.encode(test_data, bos = True, eos = True)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_counts = np.bincount([token_id for text in train_token_ids for token_id in text])\nplt.hist(token_counts, bins=100)\nplt.title('Распределение количества упоминаний токенов')\nplt.yscale('log');","execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"unknown_subwords_in_test = sum(1 for text in test_token_ids for token_id in text if token_id == 1)\nprint('Количество случаев с неизвестными n-граммами символов в валидационной выборке',\n      unknown_subwords_in_test)","execution_count":54,"outputs":[{"output_type":"stream","text":"Количество случаев с неизвестными n-граммами символов в валидационной выборке 0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ensure_lenght(txt, length,pad_value):\n    if(length>len(txt)):\n        return list(txt) + [pad_value] * (length - len(txt))\n    else:\n        return txt[:length]\n    \nclass LanguageModelDataset(Dataset):\n    def __init__(self,token_ids, chunk_length = 30,pad_value = 0):\n        self.token_ids = token_ids\n        self.chunk_length = chunk_length\n        self.pad_value = pad_value\n    def __len__(self):\n        return len(self.token_ids)\n    def __getitem__(self,item):\n        \n        text = self.token_ids[item]\n        \n        seed_part = text[1:-1]\n        target_part = text[2:]\n        \n        seed_part = np.array(ensure_lenght(seed_part,self.chunk_length,self.pad_value))\n        target_part = np.array(ensure_lenght(target_part,self.chunk_length,self.pad_value))\n        \n        return seed_part,target_part","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = LanguageModelDataset(train_token_ids, 34,pad_value = 0)\ntest_dataset =  LanguageModelDataset(test_token_ids, 34,pad_value = 0 )","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.decode(list(train_dataset[2]))","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"['trust no friend without faults and love a woman but no angel<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>',\n 'no friend without faults and love a woman but no angel<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_dependency_target_mask(size):\n    full_mask = torch.ones((size,size))\n    ignore_mask = torch.tril(full_mask)<1\n    full_mask.masked_fill_(ignore_mask,float('-inf'))\n    full_mask.masked_fill_(~ignore_mask,0)\n    return full_mask\n                    \ndef make_positional_encoding(max_len,emb_size):\n    time = np.pi * torch.arange(0,max_len).float()\n    freq_dividers = torch.arange(1,emb_size//2+1)\n    inputs = time[:, None] / freq_dividers[None, :]\n    \n    result = torch.zeros(max_len,emb_size)\n    result[:, 0::2] = torch.sin(inputs)\n    result[:, 1::2] = torch.cos(inputs)\n    return result","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LanguageModel(nn.Module):\n    def __init__(self,vocab_size,emb_size,backbone,emb_dropout = 0.0):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.emb_size = emb_size\n        self.embeddings = nn.Embedding(vocab_size,emb_size,padding_idx = 0)\n        self.emb_dropout = nn.Dropout(emb_dropout)\n        self.backbone = backbone\n        self.out = nn.Linear(emb_size,vocab_size)\n        \n    def forward(self,seed_token_ids):\n        batch_size,max_in_len = seed_token_ids.shape\n        \n        seed_padding_mask = seed_token_ids == 0\n        \n        dependency_mask = make_dependency_target_mask(max_in_len).to(seed_token_ids.device)\n        \n        seed_emb = self.embeddings(seed_token_ids)\n        \n        pos_codes = make_positional_encoding(max_in_len,self.emb_size).unsqueeze(0).to(seed_token_ids.device)\n        \n        seed_emb = seed_emb + pos_codes\n        seed_emb = self.emb_dropout(seed_emb)\n        \n        target_features = seed_emb\n        target_features = self.backbone(seed_emb, mask = dependency_mask, src_key_padding_mask = seed_padding_mask)\n        logits = self.out(target_features)\n        return logits","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lm_cross_entropy(pred,target):\n    \"\"\"\n    pred - BatchSize x TargetLen x VocabSize\n    target - BatchSize x TargetLen\n    \"\"\"\n    pred_flat = pred.view(-1,pred.shape[-1])\n    target_flat = target.view(-1)\n    return F.cross_entropy(pred_flat,target_flat,ignore_index = 0)\n\ndef lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 20, factor = 0.5, verbose = True)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BatchFirstTranformerEncoder(nn.Module):\n    def __init__(self,*args,**kwargs):\n        super().__init__()\n        self.impl = nn.TransformerEncoder(*args,**kwargs)\n        self.initialize_weights()\n    def forward(self,src,*args,**kwargs):\n        src = src.transpose(0,1).contiguous()\n        result = self.impl(src,*args,**kwargs)\n        result = result.transpose(0,1).contiguous()\n        return result\n    def initialize_weights(self):\n        for param in self.impl.parameters():\n            if param.dim() > 1:\n                nn.init.xavier_uniform_(param)","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LanguageModel(tokenizer.vocab_size(),128,BatchFirstTranformerEncoder(nn.TransformerEncoderLayer(d_model = 128,\n                                                                                             nhead = 8,\n                                                                                             dim_feedforward=512,\n                                                                                             dropout=0.2),num_layers = 2),emb_dropout = 0.2)","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(best_val_loss,\n best_torch_transf_model) = train_eval_loop(model,\n                                            train_dataset,\n                                            test_dataset,\n                                            lm_cross_entropy,\n                                            lr=2e-3,\n                                            epoch_n=1000,\n                                            batch_size=1024,\n                                            device='cuda',\n                                            early_stopping_patience=50,\n                                            max_batches_per_epoch_train=1000,\n                                            max_batches_per_epoch_val=1000,\n                                            lr_scheduler_ctor=lr_scheduler)","execution_count":70,"outputs":[{"output_type":"stream","text":"Эпоха 0\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 6.381273337772915\nСреднее значение функции потерь на валидации 6.080692807833354\nНовая лучшая модель!\n\nЭпоха 1\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 5.922126804079328\nСреднее значение функции потерь на валидации 5.598604003588359\nНовая лучшая модель!\n\nЭпоха 2\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 5.505689263343811\nСреднее значение функции потерь на валидации 5.191737691561381\nНовая лучшая модель!\n\nЭпоха 3\nЭпоха: 28 итераций, 3.13 сек\nСреднее значение функции потерь на обучении 5.192608850342887\nСреднее значение функции потерь на валидации 4.934783418973287\nНовая лучшая модель!\n\nЭпоха 4\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.98303701196398\nСреднее значение функции потерь на валидации 4.776018142700195\nНовая лучшая модель!\n\nЭпоха 5\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 4.846127510070801\nСреднее значение функции потерь на валидации 4.677095333735148\nНовая лучшая модель!\n\nЭпоха 6\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.7489127942493985\nСреднее значение функции потерь на валидации 4.611823002497355\nНовая лучшая модель!\n\nЭпоха 7\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.6809753349849155\nСреднее значение функции потерь на валидации 4.5569199323654175\nНовая лучшая модель!\n\nЭпоха 8\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.622991340500968\nСреднее значение функции потерь на валидации 4.511023918787639\nНовая лучшая модель!\n\nЭпоха 9\nЭпоха: 28 итераций, 2.76 сек\nСреднее значение функции потерь на обучении 4.577151468821934\nСреднее значение функции потерь на валидации 4.4743028084437055\nНовая лучшая модель!\n\nЭпоха 10\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 4.5394488743373325\nСреднее значение функции потерь на валидации 4.438726385434468\nНовая лучшая модель!\n\nЭпоха 11\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.505044477326529\nСреднее значение функции потерь на валидации 4.411949157714844\nНовая лучшая модель!\n\nЭпоха 12\nЭпоха: 28 итераций, 2.77 сек\nСреднее значение функции потерь на обучении 4.473134160041809\nСреднее значение функции потерь на валидации 4.391754190127055\nНовая лучшая модель!\n\nЭпоха 13\nЭпоха: 28 итераций, 2.85 сек\nСреднее значение функции потерь на обучении 4.447796293667385\nСреднее значение функции потерь на валидации 4.365564823150635\nНовая лучшая модель!\n\nЭпоха 14\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.4248204571860175\nСреднее значение функции потерь на валидации 4.346224427223206\nНовая лучшая модель!\n\nЭпоха 15\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.399516292980739\nСреднее значение функции потерь на валидации 4.330566048622131\nНовая лучшая модель!\n\nЭпоха 16\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.382879086903164\nСреднее значение функции потерь на валидации 4.313079436620076\nНовая лучшая модель!\n\nЭпоха 17\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.362961343356541\nСреднее значение функции потерь на валидации 4.297891894976298\nНовая лучшая модель!\n\nЭпоха 18\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.345911656107221\nСреднее значение функции потерь на валидации 4.283952911694844\nНовая лучшая модель!\n\nЭпоха 19\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.330311145101275\nСреднее значение функции потерь на валидации 4.270190437634786\nНовая лучшая модель!\n\nЭпоха 20\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.31625645501273\nСреднее значение функции потерь на валидации 4.2616573969523115\nНовая лучшая модель!\n\nЭпоха 21\nЭпоха: 28 итераций, 3.04 сек\nСреднее значение функции потерь на обучении 4.300471680504935\nСреднее значение функции потерь на валидации 4.247707883516948\nНовая лучшая модель!\n\nЭпоха 22\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.288906420980181\nСреднее значение функции потерь на валидации 4.238702178001404\nНовая лучшая модель!\n\nЭпоха 23\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.27620347908565\nСреднее значение функции потерь на валидации 4.2279052734375\nНовая лучшая модель!\n\nЭпоха 24\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 4.267281242779323\nСреднее значение функции потерь на валидации 4.221773664156596\nНовая лучшая модель!\n\nЭпоха 25\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.2558300495147705\nСреднее значение функции потерь на валидации 4.213069041570027\nНовая лучшая модель!\n\nЭпоха 26\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.243446145738874\nСреднее значение функции потерь на валидации 4.206044912338257\nНовая лучшая модель!\n\nЭпоха 27\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 4.234659620693752\nСреднее значение функции потерь на валидации 4.2015044291814165\nНовая лучшая модель!\n\nЭпоха 28\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.2266639811652045\nСреднее значение функции потерь на валидации 4.191308657328288\nНовая лучшая модель!\n\nЭпоха 29\nЭпоха: 28 итераций, 2.86 сек\nСреднее значение функции потерь на обучении 4.218036566461835\nСреднее значение функции потерь на валидации 4.186064879099528\nНовая лучшая модель!\n\nЭпоха 30\nЭпоха: 28 итераций, 3.15 сек\nСреднее значение функции потерь на обучении 4.209355592727661\nСреднее значение функции потерь на валидации 4.178895751635234\nНовая лучшая модель!\n\nЭпоха 31\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 4.201482738767352\nСреднее значение функции потерь на валидации 4.173193494478862\nНовая лучшая модель!\n\nЭпоха 32\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 4.194980331829616\nСреднее значение функции потерь на валидации 4.166886170705159\nНовая лучшая модель!\n\nЭпоха 33\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.186708280018398\nСреднее значение функции потерь на валидации 4.16206415494283\nНовая лучшая модель!\n\nЭпоха 34\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 4.178504773548672\nСреднее значение функции потерь на валидации 4.157895406087239\nНовая лучшая модель!\n\nЭпоха 35\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 4.169465269361224\nСреднее значение функции потерь на валидации 4.152825951576233\nНовая лучшая модель!\n\nЭпоха 36\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.165022986275809\nСреднее значение функции потерь на валидации 4.148983081181844\nНовая лучшая модель!\n\nЭпоха 37\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.1595562526157925\nСреднее значение функции потерь на валидации 4.14660116036733\nНовая лучшая модель!\n\nЭпоха 38\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.153424637658255\nСреднее значение функции потерь на валидации 4.139309287071228\nНовая лучшая модель!\n\nЭпоха 39\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 4.148051244871957\nСреднее значение функции потерь на валидации 4.139234741528829\nНовая лучшая модель!\n\nЭпоха 40\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.138578976903643\nСреднее значение функции потерь на валидации 4.1350927750269575\nНовая лучшая модель!\n\nЭпоха 41\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.137449877602713\nСреднее значение функции потерь на валидации 4.1285048723220825\nНовая лучшая модель!\n\nЭпоха 42\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 4.131120307104928\nСреднее значение функции потерь на валидации 4.123718023300171\nНовая лучшая модель!\n\nЭпоха 43\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.126177327973502\nСреднее значение функции потерь на валидации 4.121807932853699\nНовая лучшая модель!\n\nЭпоха 44\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 4.120613983699253\n","name":"stdout"},{"output_type":"stream","text":"Среднее значение функции потерь на валидации 4.1188987493515015\nНовая лучшая модель!\n\nЭпоха 45\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.1142071315220425\nСреднее значение функции потерь на валидации 4.115487734476726\nНовая лучшая модель!\n\nЭпоха 46\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 4.1089102029800415\nСреднее значение функции потерь на валидации 4.110737403233846\nНовая лучшая модель!\n\nЭпоха 47\nЭпоха: 28 итераций, 2.87 сек\nСреднее значение функции потерь на обучении 4.104091831615993\nСреднее значение функции потерь на валидации 4.1098655462265015\nНовая лучшая модель!\n\nЭпоха 48\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 4.098713517189026\nСреднее значение функции потерь на валидации 4.10413642724355\nНовая лучшая модель!\n\nЭпоха 49\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.09728331225259\nСреднее значение функции потерь на валидации 4.105313102404277\n\nЭпоха 50\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.092038444110325\nСреднее значение функции потерь на валидации 4.101470311482747\nНовая лучшая модель!\n\nЭпоха 51\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.087772147996085\nСреднее значение функции потерь на валидации 4.097606698671977\nНовая лучшая модель!\n\nЭпоха 52\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.084789122853961\nСреднее значение функции потерь на валидации 4.0957053899765015\nНовая лучшая модель!\n\nЭпоха 53\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.081712297030857\nСреднее значение функции потерь на валидации 4.09062643845876\nНовая лучшая модель!\n\nЭпоха 54\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.076708112444196\nСреднее значение функции потерь на валидации 4.091386119524638\n\nЭпоха 55\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.07456248147147\nСреднее значение функции потерь на валидации 4.086811502774556\nНовая лучшая модель!\n\nЭпоха 56\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.070816840444293\nСреднее значение функции потерь на валидации 4.084403435389201\nНовая лучшая модель!\n\nЭпоха 57\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.068112237112863\nСреднее значение функции потерь на валидации 4.085116147994995\n\nЭпоха 58\nЭпоха: 28 итераций, 3.08 сек\nСреднее значение функции потерь на обучении 4.061068143163409\nСреднее значение функции потерь на валидации 4.080757935841878\nНовая лучшая модель!\n\nЭпоха 59\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.0611094406672885\nСреднее значение функции потерь на валидации 4.080039103825887\nНовая лучшая модель!\n\nЭпоха 60\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.055497918810163\nСреднее значение функции потерь на валидации 4.0782811641693115\nНовая лучшая модель!\n\nЭпоха 61\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 4.0517578125\nСреднее значение функции потерь на валидации 4.075152476628621\nНовая лучшая модель!\n\nЭпоха 62\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.046684452465603\nСреднее значение функции потерь на валидации 4.075739781061809\n\nЭпоха 63\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 4.045342036655971\nСреднее значение функции потерь на валидации 4.071333209673564\nНовая лучшая модель!\n\nЭпоха 64\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.041328702654157\nСреднее значение функции потерь на валидации 4.069668094317119\nНовая лучшая модель!\n\nЭпоха 65\nЭпоха: 28 итераций, 2.76 сек\nСреднее значение функции потерь на обучении 4.039581494671958\nСреднее значение функции потерь на валидации 4.06783123811086\nНовая лучшая модель!\n\nЭпоха 66\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.036314845085144\nСреднее значение функции потерь на валидации 4.067533731460571\nНовая лучшая модель!\n\nЭпоха 67\nЭпоха: 28 итераций, 3.10 сек\nСреднее значение функции потерь на обучении 4.031961406980242\nСреднее значение функции потерь на валидации 4.067819873491923\n\nЭпоха 68\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 4.031296099935259\nСреднее значение функции потерь на валидации 4.0628403425216675\nНовая лучшая модель!\n\nЭпоха 69\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 4.026328095367977\nСреднее значение функции потерь на валидации 4.063325007756551\n\nЭпоха 70\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.0258902822222025\nСреднее значение функции потерь на валидации 4.058264374732971\nНовая лучшая модель!\n\nЭпоха 71\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.021831955228533\nСреднее значение функции потерь на валидации 4.060355067253113\n\nЭпоха 72\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.020278624125889\nСреднее значение функции потерь на валидации 4.054264783859253\nНовая лучшая модель!\n\nЭпоха 73\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 4.016893131392343\nСреднее значение функции потерь на валидации 4.054303685824077\n\nЭпоха 74\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 4.015547394752502\nСреднее значение функции потерь на валидации 4.052254875500997\nНовая лучшая модель!\n\nЭпоха 75\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.01137386901038\nСреднее значение функции потерь на валидации 4.052614529927571\n\nЭпоха 76\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 4.0105904425893515\nСреднее значение функции потерь на валидации 4.049749771753947\nНовая лучшая модель!\n\nЭпоха 77\nЭпоха: 28 итераций, 3.07 сек\nСреднее значение функции потерь на обучении 4.006699945245471\nСреднее значение функции потерь на валидации 4.0458195606867475\nНовая лучшая модель!\n\nЭпоха 78\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.002998224326542\nСреднее значение функции потерь на валидации 4.048028866449992\n\nЭпоха 79\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 4.002560198307037\nСреднее значение функции потерь на валидации 4.046465913454692\n\nЭпоха 80\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 4.001738088471549\nСреднее значение функции потерь на валидации 4.043254295984904\nНовая лучшая модель!\n\nЭпоха 81\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.9967438834054128\nСреднее значение функции потерь на валидации 4.04586390654246\n\nЭпоха 82\nЭпоха: 28 итераций, 2.86 сек\nСреднее значение функции потерь на обучении 3.9955300518444608\nСреднее значение функции потерь на валидации 4.040850599606832\nНовая лучшая модель!\n\nЭпоха 83\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.992745416504996\nСреднее значение функции потерь на валидации 4.042194088300069\n\nЭпоха 84\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.9923646535192217\nСреднее значение функции потерь на валидации 4.041202028592427\n\nЭпоха 85\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.9867269481931413\nСреднее значение функции потерь на валидации 4.040937622388204\n\nЭпоха 86\nЭпоха: 28 итераций, 3.06 сек\nСреднее значение функции потерь на обучении 3.9865929314068387\nСреднее значение функции потерь на валидации 4.03500501314799\nНовая лучшая модель!\n\nЭпоха 87\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.9844706739698137\nСреднее значение функции потерь на валидации 4.033665855725606\nНовая лучшая модель!\n\nЭпоха 88\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.982621192932129\nСреднее значение функции потерь на валидации 4.032839298248291\nНовая лучшая модель!\n\nЭпоха 89\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.9832335114479065\nСреднее значение функции потерь на валидации 4.0330833196640015\n\nЭпоха 90\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.9783033984048024\nСреднее значение функции потерь на валидации 4.035210967063904\n\nЭпоха 91\n","name":"stdout"},{"output_type":"stream","text":"Эпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.975362079484122\nСреднее значение функции потерь на валидации 4.032335996627808\nНовая лучшая модель!\n\nЭпоха 92\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.975139081478119\nСреднее значение функции потерь на валидации 4.030007998148601\nНовая лучшая модель!\n\nЭпоха 93\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.9745149442127774\nСреднее значение функции потерь на валидации 4.028994560241699\nНовая лучшая модель!\n\nЭпоха 94\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.97181499004364\nСреднее значение функции потерь на валидации 4.028562347094218\nНовая лучшая модель!\n\nЭпоха 95\nЭпоха: 28 итераций, 3.02 сек\nСреднее значение функции потерь на обучении 3.967358274119241\nСреднее значение функции потерь на валидации 4.0273706912994385\nНовая лучшая модель!\n\nЭпоха 96\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.969037856374468\nСреднее значение функции потерь на валидации 4.023990233739217\nНовая лучшая модель!\n\nЭпоха 97\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.963685257094247\nСреднее значение функции потерь на валидации 4.024276494979858\n\nЭпоха 98\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.9642310994012013\nСреднее значение функции потерь на валидации 4.0241519411404925\n\nЭпоха 99\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.961346779550825\nСреднее значение функции потерь на валидации 4.025624215602875\n\nЭпоха 100\nЭпоха: 28 итераций, 2.86 сек\nСреднее значение функции потерь на обучении 3.961214934076582\nСреднее значение функции потерь на валидации 4.0224418838818865\nНовая лучшая модель!\n\nЭпоха 101\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.9589034148624966\nСреднее значение функции потерь на валидации 4.021869917710622\nНовая лучшая модель!\n\nЭпоха 102\nЭпоха: 28 итераций, 2.80 сек\nСреднее значение функции потерь на обучении 3.9568542412349155\nСреднее значение функции потерь на валидации 4.020843207836151\nНовая лучшая модель!\n\nЭпоха 103\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.955252136502947\nСреднее значение функции потерь на валидации 4.0197060108184814\nНовая лучшая модель!\n\nЭпоха 104\nЭпоха: 28 итераций, 3.01 сек\nСреднее значение функции потерь на обучении 3.952444016933441\nСреднее значение функции потерь на валидации 4.017860968907674\nНовая лучшая модель!\n\nЭпоха 105\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.9511643988745555\nСреднее значение функции потерь на валидации 4.017734785874684\nНовая лучшая модель!\n\nЭпоха 106\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.9493575436728343\nСреднее значение функции потерь на валидации 4.019073983033498\n\nЭпоха 107\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.9481573360306874\nСреднее значение функции потерь на валидации 4.017797450224559\n\nЭпоха 108\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.9468308857509067\nСреднее значение функции потерь на валидации 4.016929467519124\nНовая лучшая модель!\n\nЭпоха 109\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.945529052189418\nСреднее значение функции потерь на валидации 4.0150630076726275\nНовая лучшая модель!\n\nЭпоха 110\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.9440674611500333\nСреднее значение функции потерь на валидации 4.017555395762126\n\nЭпоха 111\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.9426566873277937\nСреднее значение функции потерь на валидации 4.0113204916318255\nНовая лучшая модель!\n\nЭпоха 112\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.9413585577692305\nСреднее значение функции потерь на валидации 4.0114684502283735\n\nЭпоха 113\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.9387596419879367\nСреднее значение функции потерь на валидации 4.015045464038849\n\nЭпоха 114\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.9367350935935974\nСреднее значение функции потерь на валидации 4.0112796028455096\nНовая лучшая модель!\n\nЭпоха 115\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.9342560342379977\nСреднее значение функции потерь на валидации 4.010913173357646\nНовая лучшая модель!\n\nЭпоха 116\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.934857359954289\nСреднее значение функции потерь на валидации 4.008805652459462\nНовая лучшая модель!\n\nЭпоха 117\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.9329202600887845\nСреднее значение функции потерь на валидации 4.007336835066478\nНовая лучшая модель!\n\nЭпоха 118\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.934235998562404\nСреднее значение функции потерь на валидации 4.008509794871013\n\nЭпоха 119\nЭпоха: 28 итераций, 2.83 сек\nСреднее значение функции потерь на обучении 3.930986166000366\nСреднее значение функции потерь на валидации 4.010189771652222\n\nЭпоха 120\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.928552176271166\nСреднее значение функции потерь на валидации 4.008551915486653\n\nЭпоха 121\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.9284746646881104\nСреднее значение функции потерь на валидации 4.006002525488536\nНовая лучшая модель!\n\nЭпоха 122\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.92660562481199\nСреднее значение функции потерь на валидации 4.004547735055287\nНовая лучшая модель!\n\nЭпоха 123\nЭпоха: 28 итераций, 3.03 сек\nСреднее значение функции потерь на обучении 3.9263304386820113\nСреднее значение функции потерь на валидации 4.007234235604604\n\nЭпоха 124\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.9248185583523343\nСреднее значение функции потерь на валидации 4.002371191978455\nНовая лучшая модель!\n\nЭпоха 125\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.922933714730399\nСреднее значение функции потерь на валидации 4.003432710965474\n\nЭпоха 126\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.9222583259854997\nСреднее значение функции потерь на валидации 4.002746959527333\n\nЭпоха 127\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.918615298611777\nСреднее значение функции потерь на валидации 4.000202675660451\nНовая лучшая модель!\n\nЭпоха 128\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.91736376285553\nСреднее значение функции потерь на валидации 4.002623955408732\n\nЭпоха 129\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.9181966355868747\nСреднее значение функции потерь на валидации 4.004181603590648\n\nЭпоха 130\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.915808226381029\nСреднее значение функции потерь на валидации 4.002134422461192\n\nЭпоха 131\nЭпоха: 28 итераций, 2.76 сек\nСреднее значение функции потерь на обучении 3.914606750011444\nСреднее значение функции потерь на валидации 3.9992101192474365\nНовая лучшая модель!\n\nЭпоха 132\nЭпоха: 28 итераций, 3.10 сек\nСреднее значение функции потерь на обучении 3.913086014134543\nСреднее значение функции потерь на валидации 4.000110467274983\n\nЭпоха 133\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.914122428212847\nСреднее значение функции потерь на валидации 4.003096739451091\n\nЭпоха 134\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.911277541092464\nСреднее значение функции потерь на валидации 4.000741382439931\n\nЭпоха 135\nЭпоха: 28 итераций, 2.91 сек\nСреднее значение функции потерь на обучении 3.911035418510437\nСреднее значение функции потерь на валидации 3.9996243119239807\n\nЭпоха 136\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.909460893699101\nСреднее значение функции потерь на валидации 3.998053789138794\nНовая лучшая модель!\n\nЭпоха 137\nЭпоха: 28 итераций, 2.81 сек\nСреднее значение функции потерь на обучении 3.909402540751866\n","name":"stdout"},{"output_type":"stream","text":"Среднее значение функции потерь на валидации 3.9973233342170715\nНовая лучшая модель!\n\nЭпоха 138\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.9076477033751353\nСреднее значение функции потерь на валидации 3.9966522455215454\nНовая лучшая модель!\n\nЭпоха 139\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.904096645968301\nСреднее значение функции потерь на валидации 3.9952046275138855\nНовая лучшая модель!\n\nЭпоха 140\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.9057642817497253\nСреднее значение функции потерь на валидации 3.996839463710785\n\nЭпоха 141\nЭпоха: 28 итераций, 3.09 сек\nСреднее значение функции потерь на обучении 3.9048433559281484\nСреднее значение функции потерь на валидации 3.9962047139803567\n\nЭпоха 142\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.9043281248637607\nСреднее значение функции потерь на валидации 3.9940011898676553\nНовая лучшая модель!\n\nЭпоха 143\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.902596814291818\nСреднее значение функции потерь на валидации 3.993750830491384\nНовая лучшая модель!\n\nЭпоха 144\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8998843005725314\nСреднее значение функции потерь на валидации 3.9939218362172446\n\nЭпоха 145\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.898946796144758\nСреднее значение функции потерь на валидации 3.9934216936429343\nНовая лучшая модель!\n\nЭпоха 146\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8973337156432017\nСреднее значение функции потерь на валидации 3.9933518369992576\nНовая лучшая модель!\n\nЭпоха 147\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.897316907133375\nСреднее значение функции потерь на валидации 3.99210258324941\nНовая лучшая модель!\n\nЭпоха 148\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.896187254360744\nСреднее значение функции потерь на валидации 3.993747353553772\n\nЭпоха 149\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.895544844014304\nСреднее значение функции потерь на валидации 3.9903512597084045\nНовая лучшая модель!\n\nЭпоха 150\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.8977063298225403\nСреднее значение функции потерь на валидации 3.99078236023585\n\nЭпоха 151\nЭпоха: 28 итераций, 3.09 сек\nСреднее значение функции потерь на обучении 3.8942540543419972\nСреднее значение функции потерь на валидации 3.990104834238688\nНовая лучшая модель!\n\nЭпоха 152\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8938861744744435\nСреднее значение функции потерь на валидации 3.992289900779724\n\nЭпоха 153\nЭпоха: 28 итераций, 2.92 сек\nСреднее значение функции потерь на обучении 3.8905341029167175\nСреднее значение функции потерь на валидации 3.986479024092356\nНовая лучшая модель!\n\nЭпоха 154\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.892293189253126\nСреднее значение функции потерь на валидации 3.9892773429552713\n\nЭпоха 155\nЭпоха: 28 итераций, 2.79 сек\nСреднее значение функции потерь на обучении 3.8907045125961304\nСреднее значение функции потерь на валидации 3.988522191842397\n\nЭпоха 156\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8879894529070174\nСреднее значение функции потерь на валидации 3.989500880241394\n\nЭпоха 157\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8862543872424533\nСреднее значение функции потерь на валидации 3.989957809448242\n\nЭпоха 158\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.886906249182565\nСреднее значение функции потерь на валидации 3.987829407056173\n\nЭпоха 159\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.884628210748945\nСреднее значение функции потерь на валидации 3.9880789120992026\n\nЭпоха 160\nЭпоха: 28 итераций, 3.11 сек\nСреднее значение функции потерь на обучении 3.8862665551049367\nСреднее значение функции потерь на валидации 3.9883821606636047\n\nЭпоха 161\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.8852565033095225\nСреднее значение функции потерь на валидации 3.986176153024038\nНовая лучшая модель!\n\nЭпоха 162\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8825275557381764\nСреднее значение функции потерь на валидации 3.986124893029531\nНовая лучшая модель!\n\nЭпоха 163\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8822742700576782\nСреднее значение функции потерь на валидации 3.9861698945363364\n\nЭпоха 164\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8810333779879977\nСреднее значение функции потерь на валидации 3.9871877431869507\n\nЭпоха 165\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8809967126165117\nСреднее значение функции потерь на валидации 3.9867120583852134\n\nЭпоха 166\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.879029554980142\nСреднее значение функции потерь на валидации 3.9838338692982993\nНовая лучшая модель!\n\nЭпоха 167\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8818094304629733\nСреднее значение функции потерь на валидации 3.98279877503713\nНовая лучшая модель!\n\nЭпоха 168\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.8783501386642456\nСреднее значение функции потерь на валидации 3.9843427538871765\n\nЭпоха 169\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.878107794693538\nСреднее значение функции потерь на валидации 3.9841010371843972\n\nЭпоха 170\nЭпоха: 28 итераций, 3.18 сек\nСреднее значение функции потерь на обучении 3.8760187881333485\nСреднее значение функции потерь на валидации 3.98483806848526\n\nЭпоха 171\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.874909383910043\nСреднее значение функции потерь на валидации 3.9841754833857217\n\nЭпоха 172\nЭпоха: 28 итераций, 2.78 сек\nСреднее значение функции потерь на обучении 3.8764548557145253\nСреднее значение функции потерь на валидации 3.9821749130884805\nНовая лучшая модель!\n\nЭпоха 173\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.8748992681503296\nСреднее значение функции потерь на валидации 3.9817545811335244\nНовая лучшая модель!\n\nЭпоха 174\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.8732527238982066\nСреднее значение функции потерь на валидации 3.9832457105318704\n\nЭпоха 175\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8742015872682845\nСреднее значение функции потерь на валидации 3.9801719983418784\nНовая лучшая модель!\n\nЭпоха 176\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.869707371507372\nСреднее значение функции потерь на валидации 3.981854021549225\n\nЭпоха 177\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.8713525193078175\nСреднее значение функции потерь на валидации 3.980806132157644\n\nЭпоха 178\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.8668095810072765\nСреднее значение функции потерь на валидации 3.9788540800412497\nНовая лучшая модель!\n\nЭпоха 179\nЭпоха: 28 итераций, 3.05 сек\nСреднее значение функции потерь на обучении 3.8696569119180952\nСреднее значение функции потерь на валидации 3.9817143082618713\n\nЭпоха 180\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.866543565477644\nСреднее значение функции потерь на валидации 3.9814977645874023\n\nЭпоха 181\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.8675240193094527\nСреднее значение функции потерь на валидации 3.9820993343989053\n\nЭпоха 182\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.865415300641741\nСреднее значение функции потерь на валидации 3.9804028073946633\n\nЭпоха 183\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8656638179506575\nСреднее значение функции потерь на валидации 3.979553500811259\n\nЭпоха 184\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.865268017564501\n","name":"stdout"},{"output_type":"stream","text":"Среднее значение функции потерь на валидации 3.980306406815847\n\nЭпоха 185\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8631231614521573\nСреднее значение функции потерь на валидации 3.9760474960009256\nНовая лучшая модель!\n\nЭпоха 186\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.86394773210798\nСреднее значение функции потерь на валидации 3.9775261680285134\n\nЭпоха 187\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.8633788568632945\nСреднее значение функции потерь на валидации 3.974985738595327\nНовая лучшая модель!\n\nЭпоха 188\nЭпоха: 28 итераций, 2.86 сек\nСреднее значение функции потерь на обучении 3.8606960603169034\nСреднее значение функции потерь на валидации 3.9786193569501243\n\nЭпоха 189\nЭпоха: 28 итераций, 3.19 сек\nСреднее значение функции потерь на обучении 3.8628010409218922\nСреднее значение функции потерь на валидации 3.9765857259432473\n\nЭпоха 190\nЭпоха: 28 итераций, 2.77 сек\nСреднее значение функции потерь на обучении 3.862911752292088\nСреднее значение функции потерь на валидации 3.976870318253835\n\nЭпоха 191\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.857771337032318\nСреднее значение функции потерь на валидации 3.9774229526519775\n\nЭпоха 192\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.858687630721501\nСреднее значение функции потерь на валидации 3.9757873018582663\n\nЭпоха 193\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.857343920639583\nСреднее значение функции потерь на валидации 3.9782754381497702\n\nЭпоха 194\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.855299311024802\nСреднее значение функции потерь на валидации 3.9758912920951843\n\nЭпоха 195\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8562497156006947\nСреднее значение функции потерь на валидации 3.9766976038614907\n\nЭпоха 196\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.858242298875536\nСреднее значение функции потерь на валидации 3.9754071831703186\n\nЭпоха 197\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.8553488680294583\nСреднее значение функции потерь на валидации 3.97490002711614\nНовая лучшая модель!\n\nЭпоха 198\nЭпоха: 28 итераций, 3.04 сек\nСреднее значение функции потерь на обучении 3.8539974434035167\nСреднее значение функции потерь на валидации 3.979443351427714\n\nЭпоха 199\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.8552355085100447\nСреднее значение функции потерь на валидации 3.9768999020258584\n\nЭпоха 200\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.853355288505554\nСреднее значение функции потерь на валидации 3.975136955579122\n\nЭпоха 201\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8547520552362715\nСреднее значение функции потерь на валидации 3.975164294242859\n\nЭпоха 202\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8533977951322282\nСреднее значение функции потерь на валидации 3.9759095112482705\n\nЭпоха 203\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8496563690049306\nСреднее значение функции потерь на валидации 3.972895622253418\nНовая лучшая модель!\n\nЭпоха 204\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8502545186451504\nСреднее значение функции потерь на валидации 3.9737092653910318\n\nЭпоха 205\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8480383583477566\nСреднее значение функции потерь на валидации 3.9756160974502563\n\nЭпоха 206\nЭпоха: 28 итераций, 2.86 сек\nСреднее значение функции потерь на обучении 3.8495257581983293\nСреднее значение функции потерь на валидации 3.9732391834259033\n\nЭпоха 207\nЭпоха: 28 итераций, 2.81 сек\nСреднее значение функции потерь на обучении 3.84944019147328\nСреднее значение функции потерь на валидации 3.9726312359174094\nНовая лучшая модель!\n\nЭпоха 208\nЭпоха: 28 итераций, 3.08 сек\nСреднее значение функции потерь на обучении 3.847019008227757\nСреднее значение функции потерь на валидации 3.9739962021509805\n\nЭпоха 209\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.847547709941864\nСреднее значение функции потерь на валидации 3.9743420084317527\n\nЭпоха 210\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.845536087240492\nСреднее значение функции потерь на валидации 3.973530888557434\n\nЭпоха 211\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8480031064578464\nСреднее значение функции потерь на валидации 3.968112846215566\nНовая лучшая модель!\n\nЭпоха 212\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.844887741974422\nСреднее значение функции потерь на валидации 3.969706873099009\n\nЭпоха 213\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.843431830406189\nСреднее значение функции потерь на валидации 3.9702143470446267\n\nЭпоха 214\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8434268747057234\nСреднее значение функции потерь на валидации 3.973586142063141\n\nЭпоха 215\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8453716976302013\nСреднее значение функции потерь на валидации 3.973319967587789\n\nЭпоха 216\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8413850154195512\nСреднее значение функции потерь на валидации 3.972581624984741\n\nЭпоха 217\nЭпоха: 28 итераций, 3.02 сек\nСреднее значение функции потерь на обучении 3.843471441950117\nСреднее значение функции потерь на валидации 3.9724191427230835\n\nЭпоха 218\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.839569764477866\nСреднее значение функции потерь на валидации 3.970060706138611\n\nЭпоха 219\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.8385648897715976\nСреднее значение функции потерь на валидации 3.9703786770502725\n\nЭпоха 220\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.8427801302501132\nСреднее значение функции потерь на валидации 3.9676004449526467\nНовая лучшая модель!\n\nЭпоха 221\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8378283211163113\nСреднее значение функции потерь на валидации 3.9685925046602883\n\nЭпоха 222\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.839872317654746\nСреднее значение функции потерь на валидации 3.968705674012502\n\nЭпоха 223\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8374215194157193\nСреднее значение функции потерь на валидации 3.9690178632736206\n\nЭпоха 224\nЭпоха: 28 итераций, 2.85 сек\nСреднее значение функции потерь на обучении 3.838824825627463\nСреднее значение функции потерь на валидации 3.9675952990849814\nНовая лучшая модель!\n\nЭпоха 225\nЭпоха: 28 итераций, 2.79 сек\nСреднее значение функции потерь на обучении 3.8372920070375716\nСреднее значение функции потерь на валидации 3.969172239303589\n\nЭпоха 226\nЭпоха: 28 итераций, 2.78 сек\nСреднее значение функции потерь на обучении 3.8391661133084978\nСреднее значение функции потерь на валидации 3.9687378803888955\n\nЭпоха 227\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8366064855030606\nСреднее значение функции потерь на валидации 3.967074374357859\nНовая лучшая модель!\n\nЭпоха 228\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.8345724088805064\nСреднее значение функции потерь на валидации 3.969127655029297\n\nЭпоха 229\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8358891946928844\nСреднее значение функции потерь на валидации 3.9649983445803323\nНовая лучшая модель!\n\nЭпоха 230\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.834223738738469\nСреднее значение функции потерь на валидации 3.9679880340894065\n\nЭпоха 231\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.83414797272001\nСреднее значение функции потерь на валидации 3.9648770491282144\nНовая лучшая модель!\n\nЭпоха 232\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.833180546760559\n","name":"stdout"},{"output_type":"stream","text":"Среднее значение функции потерь на валидации 3.966730078061422\n\nЭпоха 233\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.8326919163976396\nСреднее значение функции потерь на валидации 3.9659403363863626\n\nЭпоха 234\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8323016677583968\nСреднее значение функции потерь на валидации 3.9666628241539\n\nЭпоха 235\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.83187883240836\nСреднее значение функции потерь на валидации 3.965212961037954\n\nЭпоха 236\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.8312143427985057\nСреднее значение функции потерь на валидации 3.9650288224220276\n\nЭпоха 237\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.829640277794429\nСреднее значение функции потерь на валидации 3.964125315348307\nНовая лучшая модель!\n\nЭпоха 238\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.828958477292742\nСреднее значение функции потерь на валидации 3.966462016105652\n\nЭпоха 239\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.831476058278765\nСреднее значение функции потерь на валидации 3.9657814105351767\n\nЭпоха 240\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.827485203742981\nСреднее значение функции потерь на валидации 3.9681447545687356\n\nЭпоха 241\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.82945385149547\nСреднее значение функции потерь на валидации 3.9638296365737915\nНовая лучшая модель!\n\nЭпоха 242\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.826543620654515\nСреднее значение функции потерь на валидации 3.9626187284787497\nНовая лучшая модель!\n\nЭпоха 243\nЭпоха: 28 итераций, 2.77 сек\nСреднее значение функции потерь на обучении 3.8278213483946666\nСреднее значение функции потерь на валидации 3.9669113953908286\n\nЭпоха 244\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.8270122834614346\nСреднее значение функции потерь на валидации 3.964087168375651\n\nЭпоха 245\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.827644467353821\nСреднее значение функции потерь на валидации 3.963098645210266\n\nЭпоха 246\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.825779208115169\nСреднее значение функции потерь на валидации 3.964781125386556\n\nЭпоха 247\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.826811466898237\nСреднее значение функции потерь на валидации 3.964987814426422\n\nЭпоха 248\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.8261331915855408\nСреднее значение функции потерь на валидации 3.9633158246676126\n\nЭпоха 249\nЭпоха: 28 итераций, 2.76 сек\nСреднее значение функции потерь на обучении 3.8266442162649974\nСреднее значение функции потерь на валидации 3.9637992779413858\n\nЭпоха 250\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.8261574847357616\nСреднее значение функции потерь на валидации 3.9645479122797647\n\nЭпоха 251\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.823432147502899\nСреднее значение функции потерь на валидации 3.9660149812698364\n\nЭпоха 252\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.8241515159606934\nСреднее значение функции потерь на валидации 3.9608784317970276\nНовая лучшая модель!\n\nЭпоха 253\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.82136994600296\nСреднее значение функции потерь на валидации 3.959252337614695\nНовая лучшая модель!\n\nЭпоха 254\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8223681364740645\nСреднее значение функции потерь на валидации 3.9616529742876687\n\nЭпоха 255\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8238476599965776\nСреднее значение функции потерь на валидации 3.962294081846873\n\nЭпоха 256\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.819469537053789\nСреднее значение функции потерь на валидации 3.9629825154940286\n\nЭпоха 257\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8205402408327376\nСреднее значение функции потерь на валидации 3.9623564879099527\n\nЭпоха 258\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.822241246700287\nСреднее значение функции потерь на валидации 3.9613149960835776\n\nЭпоха 259\nЭпоха: 28 итераций, 2.92 сек\nСреднее значение функции потерь на обучении 3.8199503251484463\nСреднее значение функции потерь на валидации 3.9612632195154824\n\nЭпоха 260\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.8201249752725874\nСреднее значение функции потерь на валидации 3.9617520372072854\n\nЭпоха 261\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.8201692615236555\nСреднее значение функции потерь на валидации 3.961678624153137\n\nЭпоха 262\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.8174111417361667\nСреднее значение функции потерь на валидации 3.9621187845865884\n\nЭпоха 263\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8182421156338284\nСреднее значение функции потерь на валидации 3.9607511361440024\n\nЭпоха 264\nЭпоха: 28 итераций, 3.01 сек\nСреднее значение функции потерь на обучении 3.8184400541441783\nСреднее значение функции потерь на валидации 3.965259552001953\n\nЭпоха 265\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.817845548902239\nСреднее значение функции потерь на валидации 3.9616570274035134\n\nЭпоха 266\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8170347809791565\nСреднее значение функции потерь на валидации 3.9616558949152627\n\nЭпоха 267\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8150751164981296\nСреднее значение функции потерь на валидации 3.9623789191246033\n\nЭпоха 268\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.816562524863652\nСреднее значение функции потерь на валидации 3.9633193016052246\n\nЭпоха 269\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.8152389441217696\nСреднее значение функции потерь на валидации 3.9588496486345925\nНовая лучшая модель!\n\nЭпоха 270\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.814021740640913\nСреднее значение функции потерь на валидации 3.961461325486501\n\nЭпоха 271\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.815355130604335\nСреднее значение функции потерь на валидации 3.9610069195429483\n\nЭпоха 272\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.813260112489973\nСреднее значение функции потерь на валидации 3.960686683654785\n\nЭпоха 273\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8139607906341553\nСреднее значение функции потерь на валидации 3.960973083972931\n\nЭпоха 274\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.813647653375353\nСреднее значение функции потерь на валидации 3.9596161047617593\n\nЭпоха 275\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.8104278530393327\nСреднее значение функции потерь на валидации 3.9613415201505027\n\nЭпоха 276\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.814676591328212\nСреднее значение функции потерь на валидации 3.9588305354118347\nНовая лучшая модель!\n\nЭпоха 277\nЭпоха: 28 итераций, 2.93 сек\nСреднее значение функции потерь на обучении 3.81075587442943\nСреднее значение функции потерь на валидации 3.958823263645172\nНовая лучшая модель!\n\nЭпоха 278\nЭпоха: 28 итераций, 2.85 сек\nСреднее значение функции потерь на обучении 3.8100655930382863\nСреднее значение функции потерь на валидации 3.9579471548398337\nНовая лучшая модель!\n\nЭпоха 279\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.8106382318905423\nСреднее значение функции потерь на валидации 3.95890074968338\n\nЭпоха 280\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.810825620378767\nСреднее значение функции потерь на валидации 3.9607146581014\n\nЭпоха 281\n","name":"stdout"},{"output_type":"stream","text":"Эпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8108489768845693\nСреднее значение функции потерь на валидации 3.9583279887835183\n\nЭпоха 282\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.806693570954459\nСреднее значение функции потерь на валидации 3.9584790070851645\n\nЭпоха 283\nЭпоха: 28 итераций, 3.00 сек\nСреднее значение функции потерь на обучении 3.8088907258851186\nСреднее значение функции потерь на валидации 3.9600701928138733\n\nЭпоха 284\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.807196242468698\nСреднее значение функции потерь на валидации 3.9594478209813437\n\nЭпоха 285\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.807039133140019\nСреднее значение функции потерь на валидации 3.9584004084269204\n\nЭпоха 286\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.8090705275535583\nСреднее значение функции потерь на валидации 3.9571956793467202\nНовая лучшая модель!\n\nЭпоха 287\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.805952625615256\nСреднее значение функции потерь на валидации 3.957948644955953\n\nЭпоха 288\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.809041883264269\nСреднее значение функции потерь на валидации 3.9614696304003396\n\nЭпоха 289\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.807471309389387\nСреднее значение функции потерь на валидации 3.9573402206103006\n\nЭпоха 290\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8048868009022305\nСреднее значение функции потерь на валидации 3.954593559106191\nНовая лучшая модель!\n\nЭпоха 291\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8074946062905446\nСреднее значение функции потерь на валидации 3.9595645666122437\n\nЭпоха 292\nЭпоха: 28 итераций, 3.03 сек\nСреднее значение функции потерь на обучении 3.806539331163679\nСреднее значение функции потерь на валидации 3.956614335378011\n\nЭпоха 293\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.805409380367824\nСреднее значение функции потерь на валидации 3.957547664642334\n\nЭпоха 294\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8033198288508823\nСреднее значение функции потерь на валидации 3.95680304368337\n\nЭпоха 295\nЭпоха: 28 итераций, 2.94 сек\nСреднее значение функции потерь на обучении 3.8058967845780507\nСреднее значение функции потерь на валидации 3.9592353105545044\n\nЭпоха 296\nЭпоха: 28 итераций, 2.80 сек\nСреднее значение функции потерь на обучении 3.804627384458269\nСреднее значение функции потерь на валидации 3.9580671985944114\n\nЭпоха 297\nЭпоха: 28 итераций, 2.79 сек\nСреднее значение функции потерь на обучении 3.8023449182510376\nСреднее значение функции потерь на валидации 3.9563231666882834\n\nЭпоха 298\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.8043347767421176\nСреднее значение функции потерь на валидации 3.9556255539258323\n\nЭпоха 299\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.805009594985417\nСреднее значение функции потерь на валидации 3.955671548843384\n\nЭпоха 300\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8013080528804233\nСреднее значение функции потерь на валидации 3.958493928114573\n\nЭпоха 301\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.803001642227173\nСреднее значение функции потерь на валидации 3.95462836821874\n\nЭпоха 302\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.802448264190129\nСреднее значение функции потерь на валидации 3.9553203781445823\n\nЭпоха 303\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.801162055560521\nСреднее значение функции потерь на валидации 3.958299140135447\n\nЭпоха 304\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.8005116496767317\nСреднее значение функции потерь на валидации 3.9574201107025146\n\nЭпоха 305\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.8012893285070146\nСреднее значение функции потерь на валидации 3.9538899858792624\nНовая лучшая модель!\n\nЭпоха 306\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.8022963234356473\nСреднее значение функции потерь на валидации 3.9542481501897178\n\nЭпоха 307\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.8027512090546742\nСреднее значение функции потерь на валидации 3.9562293887138367\n\nЭпоха 308\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.801542035170964\nСреднее значение функции потерь на валидации 3.955987870693207\n\nЭпоха 309\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.79934276001794\nСреднее значение функции потерь на валидации 3.9585362672805786\n\nЭпоха 310\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7979032823017667\nСреднее значение функции потерь на валидации 3.9550108512242637\n\nЭпоха 311\nЭпоха: 28 итераций, 3.05 сек\nСреднее значение функции потерь на обучении 3.7968412467411587\nСреднее значение функции потерь на валидации 3.9571680227915444\n\nЭпоха 312\nЭпоха: 28 итераций, 2.77 сек\nСреднее значение функции потерь на обучении 3.797203234263829\nСреднее значение функции потерь на валидации 3.9541168411572776\n\nЭпоха 313\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.8005708626338413\nСреднее значение функции потерь на валидации 3.9561676184336343\n\nЭпоха 314\nЭпоха: 28 итераций, 2.84 сек\nСреднее значение функции потерь на обучении 3.798344714300973\nСреднее значение функции потерь на валидации 3.955492377281189\n\nЭпоха 315\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7963041237422397\nСреднее значение функции потерь на валидации 3.954551955064138\n\nЭпоха 316\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.795334884098598\nСреднее значение функции потерь на валидации 3.9579491217931113\n\nЭпоха 317\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7953144907951355\nСреднее значение функции потерь на валидации 3.9560776948928833\n\nЭпоха 318\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.796150735446385\nСреднее значение функции потерь на валидации 3.9567670027414956\n\nЭпоха 319\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7959127596446445\nСреднее значение функции потерь на валидации 3.957335372765859\n\nЭпоха 320\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.796052634716034\nСреднее значение функции потерь на валидации 3.953845202922821\nНовая лучшая модель!\n\nЭпоха 321\nЭпоха: 28 итераций, 3.00 сек\nСреднее значение функции потерь на обучении 3.795653368745531\nСреднее значение функции потерь на валидации 3.9523600737253823\nНовая лучшая модель!\n\nЭпоха 322\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7956372925213406\nСреднее значение функции потерь на валидации 3.9548470775286355\n\nЭпоха 323\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7930966785975864\nСреднее значение функции потерь на валидации 3.953200101852417\n\nЭпоха 324\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7953371575900485\nСреднее значение функции потерь на валидации 3.9543181459108987\n\nЭпоха 325\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7944636940956116\nСреднее значение функции потерь на валидации 3.9536733826001487\n\nЭпоха 326\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.793398005621774\nСреднее значение функции потерь на валидации 3.9544769326845803\n\nЭпоха 327\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7930552193096707\nСреднее значение функции потерь на валидации 3.953708509604136\n\nЭпоха 328\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.795130823339735\nСреднее значение функции потерь на валидации 3.9522414803504944\nНовая лучшая модель!\n\nЭпоха 329\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7938632369041443\nСреднее значение функции потерь на валидации 3.952653467655182\n\nЭпоха 330\n","name":"stdout"},{"output_type":"stream","text":"Эпоха: 28 итераций, 3.32 сек\nСреднее значение функции потерь на обучении 3.791569326605116\nСреднее значение функции потерь на валидации 3.951316157976786\nНовая лучшая модель!\n\nЭпоха 331\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7927370241710117\nСреднее значение функции потерь на валидации 3.9528403679529824\n\nЭпоха 332\nЭпоха: 28 итераций, 2.80 сек\nСреднее значение функции потерь на обучении 3.7896886808531627\nСреднее значение функции потерь на валидации 3.9508692820866904\nНовая лучшая модель!\n\nЭпоха 333\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.79273191520146\nСреднее значение функции потерь на валидации 3.9511354764302573\n\nЭпоха 334\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7918761542865207\nСреднее значение функции потерь на валидации 3.950259268283844\nНовая лучшая модель!\n\nЭпоха 335\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7901110649108887\nСреднее значение функции потерь на валидации 3.9513036410013833\n\nЭпоха 336\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.7935853600502014\nСреднее значение функции потерь на валидации 3.951344311237335\n\nЭпоха 337\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7910010729517256\nСреднее значение функции потерь на валидации 3.949726184209188\nНовая лучшая модель!\n\nЭпоха 338\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7911528178623746\nСреднее значение функции потерь на валидации 3.9520525336265564\n\nЭпоха 339\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7874297414507185\nСреднее значение функции потерь на валидации 3.9504654010136924\n\nЭпоха 340\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7908726590020314\nСреднее значение функции потерь на валидации 3.9546826283137\n\nЭпоха 341\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7901876739093234\nСреднее значение функции потерь на валидации 3.9500516057014465\n\nЭпоха 342\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.789211596761431\nСреднее значение функции потерь на валидации 3.951595445473989\n\nЭпоха 343\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.790654259068625\nСреднее значение функции потерь на валидации 3.9519195357958474\n\nЭпоха 344\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.787422844341823\nСреднее значение функции потерь на валидации 3.951851566632589\n\nЭпоха 345\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7880070294652666\nСреднее значение функции потерь на валидации 3.952244202295939\n\nЭпоха 346\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.7885501299585616\nСреднее значение функции потерь на валидации 3.951541761557261\n\nЭпоха 347\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.7844879967825755\nСреднее значение функции потерь на валидации 3.9538785219192505\n\nЭпоха 348\nЭпоха: 28 итераций, 2.96 сек\nСреднее значение функции потерь на обучении 3.783732499395098\nСреднее значение функции потерь на валидации 3.95304004351298\n\nЭпоха 349\nЭпоха: 28 итераций, 3.05 сек\nСреднее значение функции потерь на обучении 3.787116765975952\nСреднее значение функции потерь на валидации 3.9502047499020896\n\nЭпоха 350\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.786003734384264\nСреднее значение функции потерь на валидации 3.952242831389109\n\nЭпоха 351\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7852978876658847\nСреднее значение функции потерь на валидации 3.9489916364351907\nНовая лучшая модель!\n\nЭпоха 352\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.787293783255986\nСреднее значение функции потерь на валидации 3.950730303923289\n\nЭпоха 353\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7845233508518765\nСреднее значение функции потерь на валидации 3.9519153833389282\n\nЭпоха 354\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7856194036347524\nСреднее значение функции потерь на валидации 3.949626167615255\n\nЭпоха 355\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7860115340777805\nСреднее значение функции потерь на валидации 3.951509396235148\n\nЭпоха 356\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.785199463367462\nСреднее значение функции потерь на валидации 3.9481849869092307\nНовая лучшая модель!\n\nЭпоха 357\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.786083664212908\nСреднее значение функции потерь на валидации 3.9502989252408347\n\nЭпоха 358\nЭпоха: 28 итераций, 3.00 сек\nСреднее значение функции потерь на обучении 3.783664958817618\nСреднее значение функции потерь на валидации 3.951220949490865\n\nЭпоха 359\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7836379323686873\nСреднее значение функции потерь на валидации 3.950707991917928\n\nЭпоха 360\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.783716917037964\nСреднее значение функции потерь на валидации 3.9528376261393228\n\nЭпоха 361\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7844582285199846\nСреднее значение функции потерь на валидации 3.9475316802660623\nНовая лучшая модель!\n\nЭпоха 362\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7818815452711925\nСреднее значение функции потерь на валидации 3.9513882398605347\n\nЭпоха 363\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.7812013030052185\nСреднее значение функции потерь на валидации 3.9492125709851584\n\nЭпоха 364\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7812303474971225\nСреднее значение функции потерь на валидации 3.9520456393559775\n\nЭпоха 365\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.782301502568381\nСреднее значение функции потерь на валидации 3.9515965978304544\n\nЭпоха 366\nЭпоха: 28 итераций, 2.97 сек\nСреднее значение функции потерь на обучении 3.781461605003902\nСреднее значение функции потерь на валидации 3.951058089733124\n\nЭпоха 367\nЭпоха: 28 итераций, 3.03 сек\nСреднее значение функции потерь на обучении 3.7831305350576128\nСреднее значение функции потерь на валидации 3.9518918792406716\n\nЭпоха 368\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.7826227119990756\nСреднее значение функции потерь на валидации 3.950003723303477\n\nЭпоха 369\nЭпоха: 28 итераций, 2.77 сек\nСреднее значение функции потерь на обучении 3.7818200417927335\nСреднее значение функции потерь на валидации 3.949484090010325\n\nЭпоха 370\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.780559233256749\nСреднее значение функции потерь на валидации 3.947728951772054\n\nЭпоха 371\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.780825069972447\nСреднее значение функции потерь на валидации 3.947835902372996\n\nЭпоха 372\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7805161561284746\nСреднее значение функции потерь на валидации 3.9506698648134866\n\nЭпоха 373\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.78010151215962\nСреднее значение функции потерь на валидации 3.950599471728007\n\nЭпоха 374\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7789107390812466\nСреднее значение функции потерь на валидации 3.9501572052637735\n\nЭпоха 375\nЭпоха: 28 итераций, 2.76 сек\nСреднее значение функции потерь на обучении 3.778599355901991\nСреднее значение функции потерь на валидации 3.950617492198944\n\nЭпоха 376\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.779144593647548\nСреднее значение функции потерь на валидации 3.951487362384796\n\nЭпоха 377\nЭпоха: 28 итераций, 3.03 сек\nСреднее значение функции потерь на обучении 3.7793140496526445\nСреднее значение функции потерь на валидации 3.9508296052614846\n\nЭпоха 378\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7793837870870317\n","name":"stdout"},{"output_type":"stream","text":"Среднее значение функции потерь на валидации 3.94859778881073\n\nЭпоха 379\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7779535140310014\nСреднее значение функции потерь на валидации 3.9504012068112693\n\nЭпоха 380\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7788089088031223\nСреднее значение функции потерь на валидации 3.948110560576121\n\nЭпоха 381\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7771719098091125\nСреднее значение функции потерь на валидации 3.948374589284261\n\nЭпоха 382\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7780955689293996\nСреднее значение функции потерь на валидации 3.9482264717419944\nEpoch   383: reducing learning rate of group 0 to 1.0000e-03.\n\nЭпоха 383\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.7649394273757935\nСреднее значение функции потерь на валидации 3.9463549653689065\nНовая лучшая модель!\n\nЭпоха 384\nЭпоха: 28 итераций, 2.80 сек\nСреднее значение функции потерь на обучении 3.760482839175633\nСреднее значение функции потерь на валидации 3.945589085419973\nНовая лучшая модель!\n\nЭпоха 385\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.7593982304845537\nСреднее значение функции потерь на валидации 3.941968321800232\nНовая лучшая модель!\n\nЭпоха 386\nЭпоха: 28 итераций, 3.07 сек\nСреднее значение функции потерь на обучении 3.755388711180006\nСреднее значение функции потерь на валидации 3.943228801091512\n\nЭпоха 387\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.754492555345808\nСреднее значение функции потерь на валидации 3.9406654834747314\nНовая лучшая модель!\n\nЭпоха 388\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.755209582192557\nСреднее значение функции потерь на валидации 3.941663702329\n\nЭпоха 389\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.753889424460275\nСреднее значение функции потерь на валидации 3.9439646204312644\n\nЭпоха 390\nЭпоха: 28 итераций, 2.65 сек\nСреднее значение функции потерь на обучении 3.7540831991604398\nСреднее значение функции потерь на валидации 3.9421511689821878\n\nЭпоха 391\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.750847041606903\nСреднее значение функции потерь на валидации 3.94229785601298\n\nЭпоха 392\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.7528746724128723\nСреднее значение функции потерь на валидации 3.9418529073397317\n\nЭпоха 393\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7505339554377963\nСреднее значение функции потерь на валидации 3.943590680758158\n\nЭпоха 394\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7505933897835866\nСреднее значение функции потерь на валидации 3.942785084247589\n\nЭпоха 395\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7500494803701128\nСреднее значение функции потерь на валидации 3.942698140939077\n\nЭпоха 396\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.750365836279733\nСреднее значение функции потерь на валидации 3.9419769843419394\n\nЭпоха 397\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7507228425570895\nСреднее значение функции потерь на валидации 3.9437890450159707\n\nЭпоха 398\nЭпоха: 28 итераций, 2.65 сек\nСреднее значение функции потерь на обучении 3.7508781467165266\nСреднее значение функции потерь на валидации 3.943728228410085\n\nЭпоха 399\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.749318548611232\nСреднее значение функции потерь на валидации 3.942985236644745\n\nЭпоха 400\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.74878523179463\nСреднее значение функции потерь на валидации 3.9404560327529907\nНовая лучшая модель!\n\nЭпоха 401\nЭпоха: 28 итераций, 2.85 сек\nСреднее значение функции потерь на обучении 3.747687501566751\nСреднее значение функции потерь на валидации 3.9427704016367593\n\nЭпоха 402\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.7467562471117293\nСреднее значение функции потерь на валидации 3.9425493677457175\n\nЭпоха 403\nЭпоха: 28 итераций, 2.84 сек\nСреднее значение функции потерь на обучении 3.7504597902297974\nСреднее значение функции потерь на валидации 3.9425666332244873\n\nЭпоха 404\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.7466531906809126\nСреднее значение функции потерь на валидации 3.942878484725952\n\nЭпоха 405\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7461452313831876\nСреднее значение функции потерь на валидации 3.940879762172699\n\nЭпоха 406\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.746267352785383\nСреднее значение функции потерь на валидации 3.9420160055160522\n\nЭпоха 407\nЭпоха: 28 итераций, 2.65 сек\nСреднее значение функции потерь на обучении 3.748957199709756\nСреднее значение функции потерь на валидации 3.9408650596936545\n\nЭпоха 408\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7470129983765736\nСреднее значение функции потерь на валидации 3.942479153474172\nEpoch   409: reducing learning rate of group 0 to 5.0000e-04.\n\nЭпоха 409\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7382612909589494\nСреднее значение функции потерь на валидации 3.9408666690190635\n\nЭпоха 410\nЭпоха: 28 итераций, 2.65 сек\nСреднее значение функции потерь на обучении 3.7385134441511974\nСреднее значение функции потерь на валидации 3.9404490987459817\nНовая лучшая модель!\n\nЭпоха 411\nЭпоха: 28 итераций, 2.65 сек\nСреднее значение функции потерь на обучении 3.736434212752751\nСреднее значение функции потерь на валидации 3.9397972027460733\nНовая лучшая модель!\n\nЭпоха 412\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.736881903239659\nСреднее значение функции потерь на валидации 3.9393551548322043\nНовая лучшая модель!\n\nЭпоха 413\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.735182455607823\nСреднее значение функции потерь на валидации 3.940148413181305\n\nЭпоха 414\nЭпоха: 28 итераций, 3.05 сек\nСреднее значение функции потерь на обучении 3.7376422030585155\nСреднее значение функции потерь на валидации 3.9399412075678506\n\nЭпоха 415\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.737217196396419\nСреднее значение функции потерь на валидации 3.9394546349843345\n\nЭпоха 416\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.735039302280971\nСреднее значение функции потерь на валидации 3.9394973715146384\n\nЭпоха 417\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7352835876601085\nСреднее значение функции потерь на валидации 3.9397538105646768\n\nЭпоха 418\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.7337390099252974\nСреднее значение функции потерь на валидации 3.9400229454040527\n\nЭпоха 419\nЭпоха: 28 итераций, 2.90 сек\nСреднее значение функции потерь на обучении 3.734841389315469\nСреднее значение функции потерь на валидации 3.939891298611959\n\nЭпоха 420\nЭпоха: 28 итераций, 2.76 сек\nСреднее значение функции потерь на обучении 3.733252695628575\nСреднее значение функции потерь на валидации 3.9386045932769775\nНовая лучшая модель!\n\nЭпоха 421\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.734728378908975\nСреднее значение функции потерь на валидации 3.93949023882548\n\nЭпоха 422\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7341919371059964\nСреднее значение функции потерь на валидации 3.9387665589650473\n\nЭпоха 423\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7332929117339\nСреднее значение функции потерь на валидации 3.9383761485417685\nНовая лучшая модель!\n\nЭпоха 424\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7340202842439925\nСреднее значение функции потерь на валидации 3.9375526309013367\nНовая лучшая модель!\n\nЭпоха 425\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7331150003841946\nСреднее значение функции потерь на валидации 3.938445031642914\n\nЭпоха 426\n","name":"stdout"},{"output_type":"stream","text":"Эпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.732451779501779\nСреднее значение функции потерь на валидации 3.9387250542640686\n\nЭпоха 427\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7313002943992615\nСреднее значение функции потерь на валидации 3.938959320386251\n\nЭпоха 428\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.735133537224361\nСреднее значение функции потерь на валидации 3.939483722050985\n\nЭпоха 429\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7330627271107266\nСреднее значение функции потерь на валидации 3.9389341274897256\n\nЭпоха 430\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.732257059642247\nСреднее значение функции потерь на валидации 3.9389073053995767\n\nЭпоха 431\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.731546555246626\nСреднее значение функции потерь на валидации 3.938546081384023\n\nЭпоха 432\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7319427728652954\nСреднее значение функции потерь на валидации 3.938904901345571\n\nЭпоха 433\nЭпоха: 28 итераций, 3.00 сек\nСреднее значение функции потерь на обучении 3.7323236806052074\nСреднее значение функции потерь на валидации 3.940446058909098\n\nЭпоха 434\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7332661066736494\nСреднее значение функции потерь на валидации 3.938311497370402\n\nЭпоха 435\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7296924761363437\nСреднее значение функции потерь на валидации 3.9388515750567117\n\nЭпоха 436\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.732396764414651\nСреднее значение функции потерь на валидации 3.9387917717297873\n\nЭпоха 437\nЭпоха: 28 итераций, 2.85 сек\nСреднее значение функции потерь на обучении 3.729539394378662\nСреднее значение функции потерь на валидации 3.9390931924184165\n\nЭпоха 438\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.7298982994897023\nСреднее значение функции потерь на валидации 3.9388245145479837\n\nЭпоха 439\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.730975483145033\nСреднее значение функции потерь на валидации 3.9398685892422995\n\nЭпоха 440\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7312085458210538\nСреднее значение функции потерь на валидации 3.93935497601827\n\nЭпоха 441\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.7312549352645874\nСреднее значение функции потерь на валидации 3.9385884404182434\n\nЭпоха 442\nЭпоха: 28 итераций, 3.03 сек\nСреднее значение функции потерь на обучении 3.7322356530598233\nСреднее значение функции потерь на валидации 3.937976082166036\n\nЭпоха 443\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.731846639088222\nСреднее значение функции потерь на валидации 3.9391784270604453\n\nЭпоха 444\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7307574919291904\nСреднее значение функции потерь на валидации 3.9395827054977417\n\nЭпоха 445\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.730716586112976\nСреднее значение функции потерь на валидации 3.938780744870504\nEpoch   446: reducing learning rate of group 0 to 2.5000e-04.\n\nЭпоха 446\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.729810689176832\nСреднее значение функции потерь на валидации 3.938408096631368\n\nЭпоха 447\nЭпоха: 28 итераций, 2.65 сек\nСреднее значение функции потерь на обучении 3.725539905684335\nСреднее значение функции потерь на валидации 3.9377240538597107\n\nЭпоха 448\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.725485256740025\nСреднее значение функции потерь на валидации 3.938092589378357\n\nЭпоха 449\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7248764719281877\nСреднее значение функции потерь на валидации 3.938458502292633\n\nЭпоха 450\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.726265949862344\nСреднее значение функции потерь на валидации 3.937877913316091\n\nЭпоха 451\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7242034333092824\nСреднее значение функции потерь на валидации 3.938403904438019\n\nЭпоха 452\nЭпоха: 28 итераций, 3.06 сек\nСреднее значение функции потерь на обучении 3.724351005894797\nСреднее значение функции потерь на валидации 3.9378187457720437\n\nЭпоха 453\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.7257330077035085\nСреднее значение функции потерь на валидации 3.9373496174812317\nНовая лучшая модель!\n\nЭпоха 454\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.7242799741881236\nСреднее значение функции потерь на валидации 3.9379847844441733\n\nЭпоха 455\nЭпоха: 28 итераций, 2.81 сек\nСреднее значение функции потерь на обучении 3.723802396229335\nСреднее значение функции потерь на валидации 3.938615878423055\n\nЭпоха 456\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7252017174448286\nСреднее значение функции потерь на валидации 3.938731094201406\n\nЭпоха 457\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.721992254257202\nСреднее значение функции потерь на валидации 3.9386401176452637\n\nЭпоха 458\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7233800632613048\nСреднее значение функции потерь на валидации 3.9380672375361123\n\nЭпоха 459\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7229002032961165\nСреднее значение функции потерь на валидации 3.9379802942276\n\nЭпоха 460\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7247094426836287\nСреднее значение функции потерь на валидации 3.9376175800959268\n\nЭпоха 461\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.723254842417581\nСреднее значение функции потерь на валидации 3.9379743138949075\n\nЭпоха 462\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.723085846219744\nСреднее значение функции потерь на валидации 3.937646468480428\n\nЭпоха 463\nЭпоха: 28 итераций, 2.75 сек\nСреднее значение функции потерь на обучении 3.724055196557726\nСреднее значение функции потерь на валидации 3.9378260175387063\n\nЭпоха 464\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.723141006061009\nСреднее значение функции потерь на валидации 3.9378072222073874\n\nЭпоха 465\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7238732065473283\nСреднее значение функции потерь на валидации 3.938332219918569\n\nЭпоха 466\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.724110850266048\nСреднее значение функции потерь на валидации 3.9375553528467813\nEpoch   467: reducing learning rate of group 0 to 1.2500e-04.\n\nЭпоха 467\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.720915036542075\nСреднее значение функции потерь на валидации 3.937974472840627\n\nЭпоха 468\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.721530394894736\nСреднее значение функции потерь на валидации 3.9376657605171204\n\nЭпоха 469\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.720007070473262\nСреднее значение функции потерь на валидации 3.9377633134524026\n\nЭпоха 470\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7217288187571933\nСреднее значение функции потерь на валидации 3.938059071699778\n\nЭпоха 471\nЭпоха: 28 итераций, 2.99 сек\nСреднее значение функции потерь на обучении 3.721563288143703\nСреднее значение функции потерь на валидации 3.9370713233947754\nНовая лучшая модель!\n\nЭпоха 472\nЭпоха: 28 итераций, 2.84 сек\nСреднее значение функции потерь на обучении 3.7186712622642517\nСреднее значение функции потерь на валидации 3.937985599040985\n\nЭпоха 473\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.722315396581377\nСреднее значение функции потерь на валидации 3.937159518400828\n\nЭпоха 474\nЭпоха: 28 итераций, 2.83 сек\nСреднее значение функции потерь на обучении 3.721823743411473\n","name":"stdout"},{"output_type":"stream","text":"Среднее значение функции потерь на валидации 3.9372642834981284\n\nЭпоха 475\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.721888073853084\nСреднее значение функции потерь на валидации 3.9369158943494162\nНовая лучшая модель!\n\nЭпоха 476\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7215187634740556\nСреднее значение функции потерь на валидации 3.9380250374476113\n\nЭпоха 477\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.7227359669549123\nСреднее значение функции потерь на валидации 3.937531371911367\n\nЭпоха 478\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7210061124392917\nСреднее значение функции потерь на валидации 3.9369864662488303\n\nЭпоха 479\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7221332362719943\nСреднее значение функции потерь на валидации 3.937338173389435\n\nЭпоха 480\nЭпоха: 28 итераций, 3.07 сек\nСреднее значение функции потерь на обучении 3.722758335726602\nСреднее значение функции потерь на валидации 3.937184433142344\n\nЭпоха 481\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7189731087003435\nСреднее значение функции потерь на валидации 3.9374210635821023\n\nЭпоха 482\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7200664622443065\nСреднее значение функции потерь на валидации 3.9374677538871765\n\nЭпоха 483\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7191626259258816\nСреднее значение функции потерь на валидации 3.9376461505889893\n\nЭпоха 484\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7185923201697215\nСреднее значение функции потерь на валидации 3.93777996301651\n\nЭпоха 485\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.721134500844138\nСреднее значение функции потерь на валидации 3.9373203118642173\n\nЭпоха 486\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7183400051934377\nСреднее значение функции потерь на валидации 3.93783708413442\n\nЭпоха 487\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.7201880727495467\nСреднее значение функции потерь на валидации 3.9374709526697793\n\nЭпоха 488\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.719386781964983\nСреднее значение функции потерь на валидации 3.9375240802764893\n\nЭпоха 489\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7192524671554565\nСреднее значение функции потерь на валидации 3.9371397693951926\n\nЭпоха 490\nЭпоха: 28 итераций, 3.25 сек\nСреднее значение функции потерь на обучении 3.717927728380476\nСреднее значение функции потерь на валидации 3.9370251099268594\n\nЭпоха 491\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.718708506652287\nСреднее значение функции потерь на валидации 3.9374850392341614\n\nЭпоха 492\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.7184245926993236\nСреднее значение функции потерь на валидации 3.9372238318125405\nEpoch   493: reducing learning rate of group 0 to 6.2500e-05.\n\nЭпоха 493\nЭпоха: 28 итераций, 2.76 сек\nСреднее значение функции потерь на обучении 3.7171113320759366\nСреднее значение функции потерь на валидации 3.9374890327453613\n\nЭпоха 494\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7190522296088084\nСреднее значение функции потерь на валидации 3.937140961488088\n\nЭпоха 495\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.719821648938315\nСреднее значение функции потерь на валидации 3.937364081541697\n\nЭпоха 496\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.7183662993567332\nСреднее значение функции потерь на валидации 3.9373947580655417\n\nЭпоха 497\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.719208444867815\nСреднее значение функции потерь на валидации 3.9371554851531982\n\nЭпоха 498\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.7185422778129578\nСреднее значение функции потерь на валидации 3.9374966422716775\n\nЭпоха 499\nЭпоха: 28 итераций, 2.68 сек\nСреднее значение функции потерь на обучении 3.71673526934215\nСреднее значение функции потерь на валидации 3.937133491039276\n\nЭпоха 500\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7183522837502614\nСреднее значение функции потерь на валидации 3.937476933002472\n\nЭпоха 501\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.717878886631557\nСреднее значение функции потерь на валидации 3.9375122586886087\n\nЭпоха 502\nЭпоха: 28 итераций, 2.73 сек\nСреднее значение функции потерь на обучении 3.718662202358246\nСреднее значение функции потерь на валидации 3.937538723150889\n\nЭпоха 503\nЭпоха: 28 итераций, 2.74 сек\nСреднее значение функции потерь на обучении 3.718287169933319\nСреднее значение функции потерь на валидации 3.9372645219167075\n\nЭпоха 504\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.71870642048972\nСреднее значение функции потерь на валидации 3.937129000822703\n\nЭпоха 505\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7185317192758833\nСреднее значение функции потерь на валидации 3.937114417552948\n\nЭпоха 506\nЭпоха: 28 итераций, 2.69 сек\nСреднее значение функции потерь на обучении 3.7179706692695618\nСреднее значение функции потерь на валидации 3.937259256839752\n\nЭпоха 507\nЭпоха: 28 итераций, 2.65 сек\nСреднее значение функции потерь на обучении 3.719699433871678\nСреднее значение функции потерь на валидации 3.937355856100718\n\nЭпоха 508\nЭпоха: 28 итераций, 2.93 сек\nСреднее значение функции потерь на обучении 3.717686482838222\nСреднее значение функции потерь на валидации 3.9372493624687195\n\nЭпоха 509\nЭпоха: 28 итераций, 3.02 сек\nСреднее значение функции потерь на обучении 3.7192480053220476\nСреднее значение функции потерь на валидации 3.937197665373484\n\nЭпоха 510\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.719186544418335\nСреднее значение функции потерь на валидации 3.9373077750205994\n\nЭпоха 511\nЭпоха: 28 итераций, 2.72 сек\nСреднее значение функции потерь на обучении 3.719010199819292\nСреднее значение функции потерь на валидации 3.9374533891677856\n\nЭпоха 512\nЭпоха: 28 итераций, 2.77 сек\nСреднее значение функции потерь на обучении 3.7176574809210643\nСреднее значение функции потерь на валидации 3.9373469750086465\n\nЭпоха 513\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7166680012430464\nСреднее значение функции потерь на валидации 3.9369632800420127\nEpoch   514: reducing learning rate of group 0 to 3.1250e-05.\n\nЭпоха 514\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.719185309750693\nСреднее значение функции потерь на валидации 3.9370490113894143\n\nЭпоха 515\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.715435062135969\nСреднее значение функции потерь на валидации 3.9371097485224404\n\nЭпоха 516\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.717467418738774\nСреднее значение функции потерь на валидации 3.937148114045461\n\nЭпоха 517\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7165954453604564\nСреднее значение функции потерь на валидации 3.9371912280718484\n\nЭпоха 518\nЭпоха: 28 итераций, 3.00 сек\nСреднее значение функции потерь на обучении 3.714246085711888\nСреднее значение функции потерь на валидации 3.937125265598297\n\nЭпоха 519\nЭпоха: 28 итераций, 2.71 сек\nСреднее значение функции потерь на обучении 3.715724229812622\nСреднее значение функции потерь на валидации 3.9370948672294617\n\nЭпоха 520\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.719349443912506\nСреднее значение функции потерь на валидации 3.9372679193814597\n\nЭпоха 521\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.7178236160959517\nСреднее значение функции потерь на валидации 3.937055468559265\n\nЭпоха 522\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.7179457119532993\nСреднее значение функции потерь на валидации 3.936998426914215\n\nЭпоха 523\nЭпоха: 28 итераций, 2.66 сек\nСреднее значение функции потерь на обучении 3.716012511934553\n","name":"stdout"},{"output_type":"stream","text":"Среднее значение функции потерь на валидации 3.9370716412862143\n\nЭпоха 524\nЭпоха: 28 итераций, 2.67 сек\nСреднее значение функции потерь на обучении 3.717869349888393\nСреднее значение функции потерь на валидации 3.9370112816492715\n\nЭпоха 525\nЭпоха: 28 итераций, 2.70 сек\nСреднее значение функции потерь на обучении 3.717998504638672\nСреднее значение функции потерь на валидации 3.9369606375694275\n\nЭпоха 526\nЭпоха: 28 итераций, 2.94 сек\nСреднее значение функции потерь на обучении 3.717379799910954\nСреднее значение функции потерь на валидации 3.9369558691978455\nМодель не улучшилась за последние 50 эпох, прекращаем обучение\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(best_torch_transf_model.state_dict(), 'quotes_model.pth')","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('quotes_model.pth'))","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import heapq\nclass BeamGenerator():\n    def __init__(self,model,tokenizer,device = 'cuda',eos_token_id = 3):\n        self.model = model\n        self.device = torch.device(device)\n        self.model.to(self.device)\n        self.eos_token_id = eos_token_id\n        self.tokenizer = tokenizer\n    def __call__(self,seed_text,max_steps_n = 40, beamsize = 5, return_hypotheses_n = 5):\n        \n        seed_tokens = self.tokenizer.encode([seed_text])[0]\n        initial_len = len(seed_tokens)\n        \n        partial_hyp = [(0,seed_tokens)]\n        final = []\n        \n        while(len(partial_hyp) > 0):\n            cur_partial_score, cur_partial_hyp = heapq.heappop(partial_hyp)\n            in_batch = torch.tensor(cur_partial_hyp).unsqueeze(0).to(self.device)\n            next_tokens_logits = self.model(in_batch)[0,-1]\n            next_tokens_logproba = F.log_softmax(next_tokens_logits)\n            topk_continuations = next_tokens_logproba.topk(beamsize)\n            \n            for token_score, token_idx in zip(topk_continuations.values,topk_continuations.indices):\n                \n                token_score = float(token_score)\n                token_idx = int(token_idx)\n                \n                old_denorm_score = cur_partial_score * np.sqrt(len(cur_partial_hyp))\n                new_score = (old_denorm_score - token_score) / np.sqrt(len(cur_partial_hyp)+1)\n                \n                new_hyp = cur_partial_hyp + [token_idx]\n                new_item = (new_score,new_hyp)\n                \n                if token_idx == self.eos_token_id or len(new_hyp) - initial_len >= max_steps_n:\n                    final.append(new_item)\n                else:\n                    heapq.heappush(partial_hyp,new_item)\n            if(len(partial_hyp) > beamsize):\n                partial_hyp = heapq.nsmallest(beamsize,partial_hyp)\n                heapq.heapify(partial_hyp)\n        final_scores, final_token_list = zip(*final)\n        \n        final_text = self.tokenizer.decode(list(final_token_list))\n        \n        result = list(zip(final_scores,final_text))\n        result.sort()\n        result = result[:return_hypotheses_n]\n        \n        return result\n        ","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"beam_generator = BeamGenerator(model,tokenizer)","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nbeam_gen_variants = beam_generator('love',\n                                   beamsize=10,\n                                   return_hypotheses_n=5)\n\nfor score, pred_txt in beam_gen_variants:\n    print('****')\n    print(score)\n    print(pred_txt[:-5])\n    print()","execution_count":259,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","name":"stderr"},{"output_type":"stream","text":"****\n4.020973865670746\nlove is the best thing\n\n****\n4.050088717587435\nlove does not make you happy\n\n****\n4.089896519978841\nlove is one of the most important thing\n\n****\n4.227022245172906\nlove is the best thing to do\n\n****\n4.56889533996582\nlove is one of the most beautiful things\n\nCPU times: user 1.23 s, sys: 17.5 ms, total: 1.25 s\nWall time: 1.25 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RandomGeneration():\n    def __init__(self,model,tokenizer,device = 'cuda',eos_token_id = 3):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.eos_token_id = eos_token_id\n        self.device = torch.device(device)\n        self.model.to(self.device)\n        \n    def __call__(self,seed_phrase = '  ', temperature = 1.0,max_steps_n = 1000):\n        seed_tokens = tokenizer.encode(list([seed_phrase]))[0]\n        vocab_size = (self.tokenizer.vocab_size())\n                      \n        if len (seed_tokens) == 0:\n            seed_tokens.append(2)\n                      \n        for _ in range(max_steps_n):\n            in_batch = torch.tensor(seed_tokens).unsqueeze(0).to(self.device)\n            logits = self.model(in_batch)[0,-1]\n            logproba = F.softmax(logits/temperature).cpu().detach().numpy()\n            \n            next_token = np.random.choice(vocab_size,p = logproba)\n            seed_tokens.append(next_token)\n            \n            if(next_token == self.eos_token_id): break\n        \n        return self.tokenizer.decode([seed_tokens])[0][:-5]","execution_count":238,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generation = RandomGeneration(model,tokenizer)","execution_count":239,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(10):\n    print(generation(seed_phrase = 'love',temperature = 0.5))","execution_count":263,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","name":"stderr"},{"output_type":"stream","text":"love is the last thing that is not a memory\nlove is the greatest thing that the most beautiful things are ever done\nlove is a dishonest\nlove is not a great deal of faith\nlove is a gift when you love someone you love someone else you have to be happy\nlove is the only thing that is possible if you are not to be loved\nlove is the most powerful thing in life\nlove is a good thing\nlove is a pleasant thing that is not so much more important than a man to be so large as a man\nlove is not a dreaming but only a dream of life\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RandomGenerationStepTemp():\n    def __init__(self,model,tokenizer,device = 'cuda',eos_token_id = 3):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.eos_token_id = eos_token_id\n        self.device = torch.device(device)\n        self.model.to(self.device)\n        \n    def __call__(self,seed_phrase = '  ', temperature = 1.0,size_step = 10,step = 0.1,max_steps_n = 100):\n        seed_tokens = tokenizer.encode(list([seed_phrase]))[0]\n        vocab_size = (self.tokenizer.vocab_size())\n                      \n        if len (seed_tokens) == 0:\n            seed_tokens.append(2)\n                      \n        for i in range(max_steps_n):\n            in_batch = torch.tensor(seed_tokens).unsqueeze(0).to(self.device)\n            logits = self.model(in_batch)[0,-1]\n            logproba = F.softmax(logits/temperature).cpu().detach().numpy()\n            \n            next_token = np.random.choice(vocab_size,p = logproba)\n            seed_tokens.append(next_token)\n            if(i%size_step == 0):\n                temperature = temperature - step\n                if(temperature<=0):temperature = 0.1\n            \n            if(next_token == self.eos_token_id): break\n        \n        return self.tokenizer.decode([seed_tokens])[0][:-5]","execution_count":307,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generation_step = RandomGenerationStepTemp(model,tokenizer)","execution_count":308,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(10):\n    print(generation_step(seed_phrase = 'freedom',temperature = 0.5,size_step = 2,step = 0.05))","execution_count":321,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","name":"stderr"},{"output_type":"stream","text":"freedom is a gift of life\nfreedom is the key to the united states and the mind\nfreedom is the last thing that you have to be loved\nfreedom is a choice that is the greatest virtue of the world\nfreedom is the key to happiness\nfreedom is a great thing of the most important thing to do is to be happy\nfreedom is a man who is not afraid of the world\nfreedom is a virtue of a man\nfreedom is the key to the lonely and the greatest of the world\nfreedom is not the ability to make it easier to be able to be able to be able to be a man own mind\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}